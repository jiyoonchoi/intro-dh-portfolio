{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21e057f",
   "metadata": {},
   "source": [
    "## Source\n",
    "\n",
    "[Zoë Wilkinson Saldaña, \"Sentiment Analysis for Exploratory Data Analysis,\" Programming Historian 7 (2018), https://doi.org/10.46430/phen0079.](https://programminghistorian.org/en/lessons/sentiment-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f98225b",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Sentiment analysis is the use of natural language processing to extract subjective information from a textual corpus. It does so by attempting to quantify the emotional intensity of specific words and phrases in the text at hand. In other words, it uses quantitative methods to acquire qualitative data. In this example from the Programming Historian, sentiment analysis is used as the basis for an exploratory data analysis of a case study called \"the Enron E-mail Corpus\". Exploratory data analysis is essentially a strategy of summarizing or pointing out features of interest within a dataset which would otherwise likely be overlooked. The case study introduces the Enron scandal, where the company Enron was exposed for fraud and the Enron E-mail Corpus contained over 600,000 messages.\n",
    "\n",
    "\n",
    "TODO:\n",
    "I was not able to follow the discussion of the math underlying the methods here, but the code was not too complicated to follow once I sat down and really read through it. One of the main things I learned was how complex it can be to get data into the right \"shape\" for analysis. All of the dictionaries used here were complex, but I see how it was necessary to put the data together in that way. Another thing I learned was that \"stopwords\" which are often not important for other kinds of analysis are very important when it comes to stylometry because authors often use \"stopwords\" in unique and identifiable ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a111b",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ba4ec",
   "metadata": {},
   "source": [
    "## Preparing the Data for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "102963f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we import the relevant modules from the NLTK library\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af1d2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we initialize VADER so we can use it within our Python script\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3ff644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "message_text = '''Like you, I am getting very frustrated with this process. I am genuinely trying to be as reasonable as possible. I am not trying to \"hold up\" the deal at the last minute. I'm afraid that I am being asked to take a fairly large leap of faith after this company (I don't mean the two of you -- I mean Enron) has screwed me and the people who work for me.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e3ac02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like you, I am getting very frustrated with this process.\n",
      "I am genuinely trying to be as reasonable as possible.\n",
      "I am not trying to \"hold up\" the deal at the last minute.\n",
      "I'm afraid that I am being asked to take a fairly large leap\n",
      "of faith after this company (I don't mean the two of you -- \n",
      "I mean Enron) has screwed me and the people who work for me.\n"
     ]
    }
   ],
   "source": [
    "print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "scores = sid.polarity_scores(message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e8d36d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compound: -0.3804, neg: 0.093, neu: 0.836, pos: 0.071, "
     ]
    }
   ],
   "source": [
    "# Here we loop through the keys contained in scores (pos, neu, neg, and compound scores) and print the key-value pairs on the screen\n",
    "for key in sorted(scores):\n",
    "        print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f53d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
